{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c1e9d01-9959-400f-9a8d-cb69b6b9ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bc539f-9a2d-433e-9f52-3a4e3afbcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"winequality-white.csv\")\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f281eb9e-69ea-4e64-a6d6-d56a6cf7e3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning data into parts: formative (for development) and summative (for testing) ...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop(\"quality\", axis = 1)\n",
    "y = dataset[\"quality\"]\n",
    "print('Partitioning data into parts: formative (for development) and summative (for testing) ...')\n",
    "test_size = 0.20   # means 20 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f9f384-2bb8-4d77-b87d-4bb509ea6ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Best parameters for architecture tuning: {'mlpclassifier__activation': 'relu', 'mlpclassifier__hidden_layer_sizes': (50, 50)}\n",
      "Cross-validated accuracy with best parameters: 0.5630423685553855\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with scaling and MLPClassifier\n",
    "pipeline = make_pipeline(StandardScaler(), MLPClassifier(max_iter=100, random_state = 42))\n",
    "# Task 1: Train and tune the MLPClassifier with different architectures\n",
    "param_grid_architecture = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'mlpclassifier__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search_architecture = GridSearchCV(pipeline, param_grid=param_grid_architecture, cv=3, n_jobs = -1)\n",
    "# in case the training won't converge we catch the warning and ignore it\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    grid_search_architecture.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Training set score: %f\" % grid_search_architecture.score(X_train, y_train))\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters for architecture tuning:\", grid_search_architecture.best_params_)\n",
    "print(\"Cross-validated accuracy with best parameters:\", grid_search_architecture.best_score_)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e183d5b9-a854-4059-b78b-060e9d289e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for optimizer tuning: {'mlpclassifier__learning_rate_init': 0.001, 'mlpclassifier__max_iter': 500, 'mlpclassifier__solver': 'sgd'}\n",
      "Cross-validated accuracy with best parameters: 0.5689127105666155\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Study the performance impact of varying optimizer parameters\n",
    "param_grid_optimizer = {\n",
    "    'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "    'mlpclassifier__max_iter': [200, 500],\n",
    "    'mlpclassifier__learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Use the best architecture from Task 1\n",
    "best_architecture = grid_search_architecture.best_estimator_\n",
    "\n",
    "grid_search_optimizer = GridSearchCV(best_architecture, param_grid=param_grid_optimizer, cv=3, n_jobs=-1)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "    grid_search_optimizer.fit(X_train, y_train)\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters for optimizer tuning:\", grid_search_optimizer.best_params_)\n",
    "print(\"Cross-validated accuracy with best parameters:\", grid_search_optimizer.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d74fb4-e2d3-43e9-b3a1-2e5c5a6e160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.563\n",
      "Weighted Precision on the test set: 0.539\n",
      "Weighted Recall on the test set: 0.563\n"
     ]
    }
   ],
   "source": [
    "#Task 3: Test performance of best model from task 1 and 2\n",
    "#Best model is from task 2 with accuracy of 0.5689 \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "best_model = grid_search_optimizer.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy on the test set: {accuracy:.3f}\")\n",
    "print(f\"Weighted Precision on the test set: {precision_weighted:.3f}\")\n",
    "print(f\"Weighted Recall on the test set: {recall_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "415fc54f-27ff-483f-bd42-6aa585aa8654",
   "metadata": {},
   "source": [
    "Discussion of Results:\n",
    "Accuracy (0.563): This score indicates that the classifier correctly predicts the wine quality 56.3% of the time across all classes\n",
    "Weighted Precision (0.539):A weighted precision of 0.539 means that when the model predicts a certain wine quality, it is correct approximately 53.9% of the time, taking into account the importance of each class. \n",
    "Weighted Recall (0.563): Recall (or sensitivity) measures the ratio of correctly predicted positive observations to all observations in actual class. A score of 0.563 indicates the model has a moderate ability to find all the relevant cases within each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "601e150a-3734-4f6e-b9ba-f73342eabc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM tuning: {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "Cross-validated accuracy with best parameters: 0.572996426748341\n",
      "SVM Accuracy on the test set: 0.586\n",
      "SVM Weighted Precision on the test set: 0.583\n",
      "SVM Weighted Recall on the test set: 0.586\n"
     ]
    }
   ],
   "source": [
    "#Task 4: Using SVM as another classifier to compare with MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a pipeline with scaling and SVM\n",
    "svm_pipeline = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
    "\n",
    "# Task: Train and tune the SVM\n",
    "param_grid_svm = {\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_pipeline, param_grid=param_grid_svm, cv=3, n_jobs=-1)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters for SVM tuning:\", grid_search_svm.best_params_)\n",
    "print(\"Cross-validated accuracy with best parameters:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "\n",
    "# Calculate the scores for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_weighted_svm = precision_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
    "recall_weighted_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# Print the scores for SVM\n",
    "print(f\"SVM Accuracy on the test set: {accuracy_svm:.3f}\")\n",
    "print(f\"SVM Weighted Precision on the test set: {precision_weighted_svm:.3f}\")\n",
    "print(f\"SVM Weighted Recall on the test set: {recall_weighted_svm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f8c74-2f11-4d3c-8b80-404eb0925882",
   "metadata": {},
   "source": [
    "Accuracy Comparison:\n",
    "SVM model (58.6%) with the MLPClassifier (56.3%). The SVM outperforms the MLPClassifier in terms of accuracy on the test set.\n",
    "\n",
    "Precision and Recall Comparison:\n",
    "SVM's weighted precision (58.3%) is slightly higher than the MLPClassifier's weighted precision (53.9%). Similarly, the weighted recall of the SVM (58.6%) is close to the MLPClassifier's recall (56.3%)\n",
    "\n",
    "The SVM model, with tuned hyperparameters, demonstrates slightly better performance than the MLPClassifier on the test set.\n",
    "SVMs are faster to train than neural networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
